# Words-Synonyms-Finder

The ability to discern synonyms accurately is crucial in various natural language processing (NLP) tasks. This project aims to explore and compare the performance of different word embedding models in synonym identification tasks. Word embedding models represent words in a continuous vector space, capturing semantic similarities between words. We will analyze four different models trained on diverse corpora and with distinct embedding sizes: Word2Vec trained on Google News articles, Word2Vec trained on Wikipedia articles, FastText trained on Wikipedia, and GloVe trained on Twitter data.

## Before Running the Code
Install the following modules if not previously done.

To install matplotlib:

    pip install matplotlib

To install gensim:

    pip install --upgrade gensim

To install fastText:

    pip install fasttext-wheel

To install Natural Language Toolkit:

    pip install nltk

## Running the Code
1- Upload the folder of this project.

2- Open the code with Jupyter Notebook.

3- Run all cells. 
